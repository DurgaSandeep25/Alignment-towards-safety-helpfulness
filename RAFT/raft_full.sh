N_ITER=5 # number of iters of RAFT
B=100 # Batch size of prompts to sample for every iteration
# b=500
k=8 # number of responses to sample
RM_SF="deberta"
REWARD_MODEL="OpenAssistant/reward-model-deberta-v3-large-v2" # reward model to rank

# code/ python file to sample B prompts and generate k responses for them
STEP_1="/home/jupyter/LLM_Alignment/updated_sft/scripts/generate_multiple_responses/generate_multiple_resps.py"

# folder to store the responses generated by the model in above step
RAFT_MODEL_RESPS="/home/jupyter/LLM_Alignment/updated_sft/raft-model-responses"

# code/ python file to get reward scores for all the responses generated by the model
STEP_2="/home/jupyter/LLM_Alignment/updated_sft/scripts/reward_scorer.py"

# folder to store the responses generated by the reward model in above step
RAFT_MODEL_RESPS_RSCORES="/home/jupyter/LLM_Alignment/updated_sft/raft-model-responses-scored"

# code for performing SFT
STEP_3="/home/jupyter/LLM_Alignment/updated_sft/scripts/00_sft.py"

# base model name
MODEL_NAME="dsaluru/Instruction-Tuned-LLaMa-7B-Alpaca-no-quant"

# directory to save the models
MODEL_SAVE_DIR="/home/jupyter/models"

# code to generate responses on safety tasks
STEP_4="/home/jupyter/LLM_Alignment/updated_sft/scripts/generate_responses_for_safe_datasets.py"

# directory to store the above responses
MODEL_EVAL_RESPS="/home/jupyter/LLM_Alignment/updated_sft/raft-eval-safety-resps"

# code to evaluate on accuracy on safety tasks
STEP_5="/home/jupyter/LLM_Alignment/updated_sft/scripts/llama_gaurd_safe_evaluate.py"

# folder to save the results
MODEL_SAFE_EVAL_RESULTS="/home/jupyter/LLM_Alignment/updated_sft/raft-safety-metrics"

# code to push model to hub
PUSH_TO_HUB="/home/jupyter/LLM_Alignment/updated_sft/scripts/push_to_hub.py"

# just printing parameters used
echo "Parameters for RAFT"
echo "N_ITER: ${N_ITER}"
echo "B: $B"
echo "k: $k"
echo "REWARD_MODEL: ${REWARD_MODEL}"


# RAFT algorithm
for iter in $(seq 1 $N_ITER);
do
    echo "iteration: $iter"
    # sample B prompts + generate k responses for them
    python $STEP_1 \
        --model_name_or_path $MODEL_NAME \
        --n_rows $B \
        --iteration $iter \
        --save_path ${RAFT_MODEL_RESPS}/${RM_SF}_iter_${iter}_B_${B}_k_${k}.json
    
    echo "Completed step-1 of RAFT"
    
    # Use RM to score the responses and get best score
    python $STEP_2 \
        --resps_path ${RAFT_MODEL_RESPS}/${RM_SF}_iter_${iter}_B_${B}_k_${k}.json \
        --save_path ${RAFT_MODEL_RESPS_RSCORES}/${RM_SF}_iter_${iter}_B_${B}_k_${k}.json

    
    echo "Completed step-2 of RAFT"
    # Choose best responses and do SFT
    echo $MODEL_NAME
    python $STEP_3 \
        --model_name_or_path ${MODEL_NAME} \
        --train_data_path ${RAFT_MODEL_RESPS_RSCORES}/${RM_SF}_iter_${iter}_B_${B}_k_${k}.json \
        --per_device_train_batch_size 32 \
        --per_device_eval_batch_size 32 \
        --gradient_accumulation_steps 4 \
        --learning_rate 1e-4 \
        --report_to wandb \
        --run_name ${iter}_raft_${RM_SF} \
        --max_seq_length 512 \
        --num_train_epochs 4 \
        --evaluation_strategy steps \
        --eval_steps 100 \
        --logging_strategy steps \
        --log_steps 500 \
        --logging_first_step \
        --save_strategy epoch \
        --save_steps 5 \
        --lora_rank 4 \
        --lora_alpha 16 \
        --lora_dropout 0.05 \
        --train_samples $B \
        --output_dir ${MODEL_SAVE_DIR}/${iter}_raft_${B}_${RM_SF}
        
    # generate responses on safe eval datasets
    MODEL_NAME=${MODEL_SAVE_DIR}/${iter}_raft_${B}_${RM_SF}/merged_model
    
    # generate responses from model to get ready for evaluation
    python $STEP_4 \
        --model_name_or_path $MODEL_NAME \
        --eval_resps_save_root ${MODEL_EVAL_RESPS} \
        --save_name ${iter}_raft_${RM_SF}
    
    # evaluation
    python $STEP_5 \
        --data_root ${MODEL_EVAL_RESPS}/${iter}_raft_${RM_SF} \
        --save_metrics_path ${MODEL_SAFE_EVAL_RESULTS}/${iter}_raft_${RM_SF}_safe_metrics.json \
    
#     # push model to hub
#     # python $PUSH_TO_HUB \
#     #     --model_name_or_path $MODEL_NAME \
#     #     --model_id ${iter}_raft_${B}_${RM_SF}
#     if [ "$iter" -gt 1 ]; then
#         echo "iter > 1"
#         echo "removing previous iteration model for saving space"
#         echo "previous iter: $((iter-1))_raft_${B}_${RM_SF}"
#         rm -r $MODEL_SAVE_DIR/$((iter-1))_raft_${B}_${RM_SF}
#     fi
done
